{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83402752},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"106512","input":"","pos":27,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fc547f","input":"","pos":36,"type":"cell"}
{"cell_type":"code","exec_count":100,"id":"ed70cd","input":"num = 100\nxc = np.linspace(0,5,num)\nyc = np.linspace(0,5,num)\ncart_prod = np.transpose([np.tile(xc, len(yc)), np.repeat(yc, len(xc))])\nXc = np.c_[np.ones(len(cart_prod)),cart_prod[:,1],cart_prod[:,0]]\n\nX_u = np.ones((N,3))\nX_u[:,1] = pts[:,0]\nX_u[:,2] = pts[:,1]\n\nA,Xc = scaler(X_u,Xc)\ngc = nn_predict_all(Xc,w,regression)\nsays_yeah = gc == 1\nsays_no = ~says_yeah\n\nplt.title(\"Decision boundary of NN\")\n\nplt.scatter(Xc[says_yeah][:,1],Xc[says_yeah][:,2],alpha=0.05,color='g')\nplt.scatter(Xc[says_no][:,1],Xc[says_no][:,2],alpha=0.05,color='r')\nplt.scatter(A[y==1][:,1],A[y==1][:,2],label=\"1\",alpha=0.43,c='b')\nplt.scatter(A[y!=1][:,1],A[y!=1][:,2],label=\"-1\",alpha=0.43,c='white')\nplt.legend()\nplt.show()","output":{"0":{"ename":"AssertionError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-100-1e24efa6b5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msays_yeah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msays_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0msays_yeah\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_predict_all\u001b[0;34m(X, w, regression)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_predict\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#x should have the bias node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#make sure the sizes match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: "]}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":101,"id":"7d4250","input":"def MAE(g,y):\n    \"\"\"g is the predicted outcomes and y is the actual outcomes\"\"\"\n    return np.mean(np.abs(g-y))\n\ndef RMSE(g,y):\n    \"\"\"g is the predicted outcomes and y is the actual outcomes\"\"\"\n    return np.sqrt(np.mean((g-y)**2))\n    \ndef R2(g,y):\n    \"\"\"g is the predicted outcomes and y is the actual outcomes\"\"\"\n    mu = np.mean(y)\n    SStot = np.sum((y-mu)**2)\n    SSres = np.sum((g-y)**2)\n    return 1-SSres/SStot\n    \nX = np.ones(N*2).reshape(N,2)\nX[:,1] = x_pts\nX,X = scaler(X,X)\n\ny = f_noisy\n\nD_l = np.array([X.shape[1]-1,3,3,1])\n\n\nw = nn_stoch_grad_des(X,y,D_l,eta=0.001,iterations = 10000,regression=True,sigma=1)\ng = nn_predict_all(X,w,regression=True)\n\n\nplt.plot(x_pts,g,label=\"regression line\",c='red')\nplt.plot(x,f(x),label=\"target\",c='blue')\nplt.plot(x_pts,f_noisy,'o',label=\"noisy target\",alpha=0.8,c='orange')\nplt.title(f\"MAE = {MAE(g,y):0.3}, RMSE = {RMSE(g,y):0.3}, R2={R2(g,y):0.3}\")\n\nplt.legend()\n\nplt.show()","output":{"0":{"ename":"ValueError","evalue":"cannot copy sequence with size 30 to array axis with dimension 100","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-101-a1f9c254b765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 30 to array axis with dimension 100"]}},"pos":33,"type":"cell"}
{"cell_type":"code","exec_count":102,"id":"7ada1d","input":"def test_train_split(X,y,train_percent=0.8,rand_seed=42):\n    np.random.seed(rand_seed)\n    cutoff = int(train_percent*X.shape[0])\n    shuff = np.random.permutation(X.shape[0])\n    X2 = X[shuff]\n    y2 = y[shuff]\n    X_train = X2[:cutoff]\n    X_test = X2[cutoff:]\n    y_train = y2[:cutoff]\n    y_test = y2[cutoff:]\n    return X_train,X_test,y_train,y_test\n    \n    \nD = np.loadtxt(open(\"num_data.txt\", \"rb\"), delimiter=\",\", skiprows=0)\nX = np.ones((D.shape[0],(D.shape[1]-2)+1))\nX[:,1:] = D[:,2:]\ny = 2*D[:,1] -1  # so that y in {-1,1}, not {0,1}\n\nX_train,X_test,y_train,y_test = test_train_split(X,y)\nX_train,X_test = scaler(X_train,X_test)\n\n\nD_l = np.array([X.shape[1]-1,15,5,1])\nw = nn_stoch_grad_des(X_train,y_train,D_l,iterations = 10000)\n\nprint(\"Training Error\")\ng = nn_predict_all(X_train,w)\nprint(np.mean(g != y_train))\n\n\nprint(\"Test Error\")\ng = nn_predict_all(X_test,w)\nprint(np.mean(g != y_test))","output":{"0":{"ename":"ValueError","evalue":"shapes (1,6) and (16,) not aligned: 6 (dim 1) != 16 (dim 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-521114e41c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_stoch_grad_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_stoch_grad_des\u001b[0;34m(X, y, D_l, eta, iterations, regression, sigma)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m## Update last s (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Update last xx (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,6) and (16,) not aligned: 6 (dim 1) != 16 (dim 0)"]}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":80,"id":"279058","input":"import numpy as np\ndef init_nn(D_l,sigma=1):\n    \"\"\"\n    Initialize Artificial Neural Network\n    Input:  Numpy array D_l is a list of layer sizes from 0 to L of an ANN\n    Output: A python list of weight matrixes W(l) for l = 1..L (inclusive)\n    The weight matrixes are numpy 2d arrays and are initialized from the standard\n    normal distribution.\n    \"\"\"\n    np.random.seed(22)\n    L = D_l.shape[0]-1\n    w = []\n\n    for l in range(1,L+1):\n        d_prev = D_l[l-1]\n        d_l = D_l[l]\n        W_l = np.random.randn((d_prev+1)*d_l).reshape((d_prev+1),d_l)\n        W_l = W_l*sigma #we want _small_ initial weights: sigma*max(norm(x)) << 1\n        w.append(W_l)\n    return w\n\n### Optional -- Use Xavier initialization, sigma = 4*sqrt(2/(n_inputs+n_outputs))\n\ndef forward_prop(x,w,regression = False):\n    \"\"\"\n    Input: \n        d+1 dimensional input vector x to the neural network;\n        length L-1 list w of weight matrixes\n        optional threshold (activation) function theta\n    Output:\n        An array xx of intermediate layer output values, l=0,...,L\n        An array s of intermediate layer input values, l=1,...,L\n    To be consistent with the indexing from the book, s begins with a\n    placeholder 0.  Please ignore this value.  (Notice that s is never\n    actually used in the code, and in an optimized implementation we \n    would not even compute it directly.)\n    \"\"\"\n    theta=np.tanh\n    assert(x[0]==1) #x should have the bias node\n    assert(len(x) == w[0].shape[0] ) #make sure the sizes match\n\n    xx = []\n    s = [0]  # initial zero used only to simplify indexing\n    xx.append(x)\n    l=1\n\n    for W in w[:-1]:\n        s.append(W.transpose().dot(xx[-1]))## Update s\n        xx.append(np.hstack((np.array([1]),theta(s[1]))))## Update xx\n        l += 1\n    W = w[-1]\n    ## Update last s (special case)\n    s.append(W.transpose().dot(xx[-1]))\n    if regression:\n        xx.append(s[1])## Update last xx (special case)\n    else: #classification\n        xx.append(theta(s[1]))## Update last xx (special case)\n    return xx,s\n\ndef back_prop(xx,w,yi,regression=False):\n    assert(np.isscalar(yi)) # yi is just the y value for the instance x\n    delta = []\n    L = len(w)\n    if regression:\n        ## Initialize delta\n        delta.append((2*(xx[L]-yi))*1) #delta_L, assume theta = id\n    else: #classification\n        ## Initialize delta\n        delta.append(2*((xx[L]-yi))*(1-(xx[L]**2))) #delta_L, assume theta = tanh\n    l = L-1\n    for W in reversed(w[1:]):\n        thetaprime = (1-(xx[1]))[1:] ##?? Update this\n        delta_lp1 = delta[-1]  ## delta from l+1 layer\n        delta_l = thetaprime*W.dot(delta[-1])[1:]##?? Update this, delta from layer l\n        delta.append(delta_l)\n        l -= 1\n    return list(reversed(delta))\n\ndef nn_gradient(xx,delta):\n    grad = []\n    L = len(xx)-1\n    for x,d in zip(xx[:-1],delta):\n        _x = x.reshape(x.shape[0],1)\n        _d = d.reshape(d.shape[0],1)\n        grad.append(_x.dot(_d))# Update this)\n    return grad\n\ndef nn_stoch_grad_des(X,y,D_l,eta=0.01,iterations=1000,regression = False,sigma=1):\n    np.random.seed(100)\n    w = init_nn(D_l,sigma)\n    for _iterations in range(iterations):\n        r = np.random.randint(X.shape[0])\n        x = X[r]\n        yi = y[r]\n        xx,s = forward_prop(x,w,regression)\n        delta = back_prop(xx,w,yi,regression)\n        grad = nn_gradient(xx,delta)\n        new_w = []\n        for wi,w_g in zip(w,grad):\n            new_w.append(wi - eta*w_g)\n        w = new_w\n    return w\n\ndef nn_predict(x,w,regression=False):\n    xx,s = forward_prop(x,w,regression)\n    if not regression: #classification\n        return np.sign(xx[-1])\n    else:\n        return xx[-1]\n\n\ndef nn_predict_all(X,w,regression=False):\n    g = np.ones(X.shape[0])\n    for i,x in enumerate(X):\n        g[i] = nn_predict(x,w,regression)\n    return g\n\n","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":81,"id":"e8aaa5","input":"w = init_nn(np.array([1,2,1,1]))\nw","output":{"0":{"data":{"text/plain":"[array([[-0.09194992, -1.46335065],\n        [ 1.08179168, -0.23932517]]),\n array([[-0.49112914],\n        [-1.00227201],\n        [ 0.9188215 ]]),\n array([[-1.1036321 ],\n        [ 0.62649346]])]"},"exec_count":81,"output_type":"execute_result"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":82,"id":"ce0630","input":"print(\"Testing based on Example 7.1 from the book..\")\nregression = False\nw = init_nn(np.array([1,2,1,1]))\nshapes = list(map(np.shape,w))\nprint(\"w shapes:\", shapes)\nw[0] = np.array([0.1,2]).reshape((2,1))\nw[1] = np.array([0.1,.2]).reshape((2,1))\nw[2] = np.array([0.5,0.5]).reshape((2,1))\nnewshapes = list(map(np.shape,w))\n#assert(shapes==newshapes)\nprint(\"w:\",w)\n\nx = np.array([1,2])\nxx,s =forward_prop(x,w,regression)\nprint(\"xx:\",xx)\nprint(\"s:\",s)\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Testing based on Example 7.1 from the book..\nw shapes: [(2, 2), (3, 1), (2, 1)]\nw: [array([[0.1],\n       [2. ]]), array([[0.1],\n       [0.2]]), array([[0.5],\n       [0.5]])]\nxx: [array([1, 2]), array([1.        , 0.99945084]), array([1.        , 0.99945084]), array([0.99945084])]\ns: [0, array([4.1]), array([0.29989017]), array([0.99972542])]\n"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":83,"id":"5528fe","input":"np.tanh(0.706)","output":{"0":{"data":{"text/plain":"0.608162409002161"},"exec_count":83,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":84,"id":"79ff6c","input":"print(\"Testing based on Example 7.1 from the book..\")\nregression = False\nw = init_nn(np.array([1,2,1,1]))\nshapes = list(map(np.shape,w))\nprint(\"w shapes:\", shapes)\nw[0] = np.array([0.1,2]).reshape((2,1))\nw[1] = np.array([0.1,.2]).reshape((2,1))\nw[2] = np.array([0.5,0.5]).reshape((2,1))\nnewshapes = list(map(np.shape,w))\n#assert(shapes==newshapes)\nprint(\"w:\",w)\n\nx = np.array([1,2])\nxx,s =forward_prop(x,w,regression)\nprint(\"xx:\",xx)\nprint(\"s:\",s)\n\ndelta = back_prop(xx,w,1,regression)\nprint(\"delta:\",delta)\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Testing based on Example 7.1 from the book..\nw shapes: [(2, 2), (3, 1), (2, 1)]\nw: [array([[0.1],\n       [2. ]]), array([[0.1],\n       [0.2]]), array([[0.5],\n       [0.5]])]\nxx: [array([1, 2]), array([1.        , 0.99945084]), array([1.        , 0.99945084]), array([0.99945084])]\ns: [0, array([4.1]), array([0.29989017]), array([0.99972542])]\ndelta: [array([-3.63684378e-14]), array([-3.31130108e-10]), array([-1.2059594e-06])]\n"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":85,"id":"3b0401","input":"(1-0.99999**2)*-0.44","output":{"0":{"data":{"text/plain":"-8.79995599995631e-06"},"exec_count":85,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":86,"id":"d3ed70","input":"print(\"Testing based on Example 7.1 from the book..\")\nregression = False\nw = init_nn(np.array([1,2,1,1]))\nshapes = list(map(np.shape,w))\nprint(\"w shapes:\", shapes)\nw[0] = np.array([0.1,2]).reshape((2,1))\nw[1] = np.array([0.1,.2]).reshape((2,1))\nw[2] = np.array([0.5,0.5]).reshape((2,1))\nnewshapes = list(map(np.shape,w))\n#assert(shapes==newshapes)\nprint(\"w:\",w)\n\nx = np.array([1,2])\nxx,s =forward_prop(x,w,regression)\nprint(\"xx:\",xx)\nprint(\"s:\",s)\n\ndelta = back_prop(xx,w,1,regression)\nprint(\"delta:\",delta)\nwg = nn_gradient(xx,delta)\nprint(\"gradient:\",wg)","output":{"0":{"name":"stdout","output_type":"stream","text":"Testing based on Example 7.1 from the book..\nw shapes: [(2, 2), (3, 1), (2, 1)]\nw: [array([[0.1],\n       [2. ]]), array([[0.1],\n       [0.2]]), array([[0.5],\n       [0.5]])]\nxx: [array([1, 2]), array([1.        , 0.99945084]), array([1.        , 0.99945084]), array([0.99945084])]\ns: [0, array([4.1]), array([0.29989017]), array([0.99972542])]\ndelta: [array([-3.63684378e-14]), array([-3.31130108e-10]), array([-1.2059594e-06])]\ngradient: [array([[-3.63684378e-14],\n       [-7.27368757e-14]]), array([[-3.31130108e-10],\n       [-3.30948266e-10]]), array([[-1.20595940e-06],\n       [-1.20529714e-06]])]\n"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":87,"id":"e1cb1d","input":"def scaler(X_train,X_test):\n    assert(X_train.shape[1]==X_test.shape[1])\n    sigma = np.std(X_train,axis=0)\n    zeros = np.isclose(sigma,np.zeros(sigma.shape[0]))\n    sigma[zeros] = 1\n\n    mu = np.mean(X_train,axis=0)\n    mu[0] = 0\n    X_train = (X_train-mu)/sigma\n    X_test = (X_test-mu)/sigma\n    return X_train,X_test    ","pos":14,"type":"cell"}
{"cell_type":"code","exec_count":88,"id":"e92ada","input":"import matplotlib.pyplot as plt\n\nD = np.loadtxt(open(\"num_data.txt\", \"rb\"), delimiter=\",\", skiprows=0)\n\n\nx  = D[:,8]\ny  = D[:,20]\n\nmalignant = D[:,1]==1  ## Column 1 represents benign (0) or malignant (1)\nxm = x[malignant]\nym = y[malignant]\n\nbenign = D[:,1]==0\nxb = x[benign]\nyb = y[benign]\n\nplt.scatter(xm,ym,label=\"malignant\",alpha=0.3)\nplt.scatter(xb,yb,label=\"benign\",alpha=0.3)\n\nplt.legend()\nplt.show()\n","output":{"0":{"data":{"image/png":"ad03fea70a81737f37128997ac4d52407a15b8cc","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":88,"metadata":{"image/png":{"height":411,"width":713},"needs_background":"light"},"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":90,"id":"99094a","input":"X = np.ones(D.shape[0]*3).reshape(D.shape[0],3)\nX[:,1] = D[:,20]\nX[:,2] = D[:,8]\nX,X = scaler(X,X)\n\ny = 2*malignant -1  # so that y in {-1,1}, not {0,1}\n\nregression = False\nD_l = np.array([2,3,2,1,1,2,1]) #architecture\nw = nn_stoch_grad_des(X,y,D_l,eta = .01,iterations = 2000,regression=regression)\ng = nn_predict_all(X,w,regression)\nprint(np.mean(np.sign(g) != y))\n","output":{"0":{"ename":"ValueError","evalue":"shapes (1,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-0cd0259e0f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_stoch_grad_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_stoch_grad_des\u001b[0;34m(X, y, D_l, eta, iterations, regression, sigma)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m## Update last s (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Update last xx (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,3) and (4,) not aligned: 3 (dim 1) != 4 (dim 0)"]}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":91,"id":"55a39f","input":"xm = X[:,2][malignant]\nym = X[:,1][malignant]\n\nxb = X[:,2][benign]\nyb = X[:,1][benign]\n\n\nplt.scatter(xm,ym,label=\"malignant\",alpha=0.13)\nplt.scatter(xb,yb,label=\"benign\",alpha=0.13)\nplt.title(\"Misclassified points (in red)\")\nplt.scatter(X[g!=y][:,2],X[g!=y][:,1],c='red',alpha=0.2)\nplt.show()\nplt.title(\"All points with correct classification\")\nplt.scatter(xm,ym,label=\"malignant\",alpha=0.13)\nplt.scatter(xb,yb,label=\"benign\",alpha=0.13)\n\nplt.show()\nnum = 100\nxc = np.linspace(-1,4,num)\nyc = np.linspace(-1,6,num)\ncart_prod = np.transpose([np.tile(xc, len(yc)), np.repeat(yc, len(xc))])\nXc = np.c_[np.ones(len(cart_prod)),cart_prod[:,1],cart_prod[:,0]]\n\nX,Xc = scaler(X,Xc)\ngc = nn_predict_all(Xc,w,regression)\nsays_yeah = gc == 1\nsays_no = ~says_yeah\n\n\nplt.title(\"Decision boundary of NN\")\nplt.scatter(xm,ym,label=\"malignant\",alpha=0.43)\nplt.scatter(xb,yb,label=\"benign\",alpha=0.43)\nplt.scatter(cart_prod[says_yeah][:,0],cart_prod[says_yeah][:,1],label=\"predict yes\",alpha=0.05,color='g')\nplt.scatter(cart_prod[says_no][:,0],cart_prod[says_no][:,1],label=\"predict no\",alpha=0.05,color='r')\n\nplt.legend()\nplt.show()\n\n","output":{"0":{"ename":"NameError","evalue":"name 'g' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-203740ca2015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"benign\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Misclassified points (in red)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All points with correct classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'g' is not defined"]},"1":{"data":{"image/png":"149ca42a87f0cc4b6daf32f9682a952dfbca387a","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":91,"metadata":{"image/png":{"height":426,"width":697},"needs_background":"light"},"output_type":"execute_result"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":92,"id":"34a342","input":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\nx = np.linspace(0,50,50) ## The domain\nN = 30   ## 30 sample points\nnp.random.seed(22)  # so we get the same random stuff\nshuff = np.random.permutation(len(x))\nx_pts = sorted(x[shuff][:N])  ## Pick N points at random from the domain\n\nf = np.sqrt   #The target function (no noise yet)\n\nsigma = 1/2\nnoise = np.random.randn(N)*sigma  ## Noise sampled from the normal distribution with sd=sigma\n\nf_noisy = f(x_pts) + noise   ## Noisy data\n\nplt.plot(x,f(x),label=\"target\",c='blue')\nplt.plot(x_pts,f_noisy,'o',label=\"noisy target\",alpha=0.8,c='orange')\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"fc886b9942f535fda2525184a5fc99d891825d0a","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":92,"metadata":{"image/png":{"height":414,"width":697},"needs_background":"light"},"output_type":"execute_result"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":94,"id":"faf431","input":"X = np.ones(D.shape[0]*4).reshape(D.shape[0],4)\nX[:,1] = D[:,8]\nX[:,2] = D[:,20]\nX[:,3] = D[:,15]\nX,X = scaler(X,X)\ny = 2*malignant -1  # so that y in {-1,1}, not {0,1}\n\nD_l = np.array([3,4,2,1])\nw = nn_stoch_grad_des(X,y,D_l,iterations = 1000)\ng = nn_predict_all(X,w)\nnp.mean(g != y)","output":{"0":{"ename":"ValueError","evalue":"shapes (1,3) and (5,) not aligned: 3 (dim 1) != 5 (dim 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-86539bbe533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_stoch_grad_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_stoch_grad_des\u001b[0;34m(X, y, D_l, eta, iterations, regression, sigma)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m## Update last s (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Update last xx (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,3) and (5,) not aligned: 3 (dim 1) != 5 (dim 0)"]}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":95,"id":"0245d7","input":"X = np.ones((D.shape[0],(D.shape[1]-2)+1))\nX[:,1:] = D[:,2:]\nX,X = scaler(X,X)\n\ny = 2*D[:,1] -1  # so that y in {-1,1}, not {0,1}\n\nD_l = np.array([X.shape[1]-1,5,2,1])\nw = nn_stoch_grad_des(X,y,D_l,iterations = 10000)\ng = nn_predict_all(X,w)\nnp.mean(g != y)","output":{"0":{"ename":"ValueError","evalue":"shapes (1,3) and (6,) not aligned: 3 (dim 1) != 6 (dim 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-de9129c3f99b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_stoch_grad_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_stoch_grad_des\u001b[0;34m(X, y, D_l, eta, iterations, regression, sigma)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(x, w, regression)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m## Update last s (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Update last xx (special case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,3) and (6,) not aligned: 3 (dim 1) != 6 (dim 0)"]}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":96,"id":"302555","input":"from sklearn.neural_network import MLPClassifier\n\nclf = MLPClassifier(solver='sgd', alpha=0,hidden_layer_sizes=(5,2), random_state=1,activation='tanh',max_iter=10000, learning_rate='constant', learning_rate_init=0.01)\n\nclf.fit(X, y)   \n1-clf.score(X,y)","output":{"0":{"data":{"text/plain":"0.007029876977152849"},"exec_count":96,"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":97,"id":"77f211","input":"np.random.seed(22)\nN=100\npts = np.random.rand(2*N).reshape(N,2)*5\nX = np.ones((N,3))\nX[:,1] = pts[:,0]\nX[:,2] = pts[:,1]\n\nf = lambda x: np.sin(x[1])+np.cos(x[2])\n\nR = np.apply_along_axis(f,1,X)\n\npos = R > 0\nneg = ~pos\n\ny = 2*pos-1\n\nplt.scatter(X[pos,1],X[pos,2],color=\"red\",label=\"positive\")\nplt.scatter(X[neg,1],X[neg,2],color=\"blue\",label=\"negative\")\nplt.title(\"Non linearly separable data\")\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"1abea822cc050567af15f6426c198fefa409953d","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":97,"metadata":{"image/png":{"height":426,"width":697},"needs_background":"light"},"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":98,"id":"29bc03","input":"D_l = np.array([X.shape[1]-1,6,1])\nX2,X2 = scaler(X,X)\nw = nn_stoch_grad_des(X2,y,D_l,eta=0.01,iterations = 10000)\ng = nn_predict_all(X2,w)\nnp.mean(g != y)","output":{"0":{"ename":"ValueError","evalue":"shapes (7,1) and (6,) not aligned: 1 (dim 1) != 6 (dim 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-76d7a290ee60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_stoch_grad_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_predict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mnn_stoch_grad_des\u001b[0;34m(X, y, D_l, eta, iterations, regression, sigma)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mnew_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-012be2932a35>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(xx, w, yi, regression)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mthetaprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m##?? Update this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdelta_lp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m## delta from l+1 layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mdelta_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetaprime\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m##?? Update this, delta from layer l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (7,1) and (6,) not aligned: 1 (dim 1) != 6 (dim 0)"]}},"pos":28,"type":"cell"}
{"cell_type":"code","exec_count":99,"id":"13fe15","input":"clf.fit(X, y)   \n1-clf.score(X,y)","output":{"0":{"data":{"text/plain":"0.030000000000000027"},"exec_count":99,"output_type":"execute_result"}},"pos":29,"type":"cell"}
{"cell_type":"markdown","id":"405848","input":"### Test drive\n\nI already implemented SGD for you so at this point your NN should be ready to run.  Let's play with it by trying to classify the cancer data into \"benign\" or \"malignant\".\n\nFirst we load the scaling function (scaling is hugely important for NNs) and the data.\n","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"4e1412","input":"### Part 2: Forward propagation\n\nWe will now implement the forward propagation part of the neural network algorithm.\n\nThis process is needed for back-propagation, but it is also how you \"run\" the network after you have trained it.  \n\nAs described in the docstring, the method should return `xx` which is what the book denotes as \n\n$${\\bf{x}}^{(\\mathcal{l})} \\text{ for } \\mathcal{l} = 0,\\ldots,L$$\n\nIt also returns `s` which is what the book calls \n\n\n$${\\bf{s}}^{(\\mathcal{l})} \\text{ for } \\mathcal{l} = 1,\\ldots,L$$\n\nBecause array indexing doesn't start at 1 in python I have initialized `s` to contain a placeholder 0.  This is just so that you can use the same index notation as used in the book, for example\n\n$${\\bf{s}}^{(l)} = (W^{(l)})^Tx^{(l-1)}$$\n\nwhen you write your code.\n\nIf you follow the forward propagation pseudocode from the book be sure to adjust it so that you do $l=L$ as a special case.  In particular you do not want ${\\bf{x}}^{(L)}$ to have a bias node.  You also want to do different things depending on the truth value of the `regression` function parameter. This parameter is `True` if the user intends to use the network for regression (in which case the final activation function is not applied and ${\\bf{x}}^{(L)}={\\bf{s}}^{(L)}$). For classification (when `regression` is `False`) ${\\bf{x}}^{(L)}=\\theta({\\bf{s}}^{(L)})$.\n","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"502dfa","input":"Now let's try it with all the data. \n\nCan you improve on this training error? \n","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"6400dc","input":"### Part 4: The gradient of ${\\bf{e}}$\n\nWe now fill in the code for `nn_gradient(xx,delta)`.  This function takes `xx` = $[{\\bf{x}}^{(0)},{\\bf{x}}^{(1)},\\ldots,{\\bf{x}}^{(L)},]$ and `delta` = $[{\\bf{\\delta}}^{(1)},{\\bf{\\delta}}^{(2)},\\ldots,{\\bf{\\delta}}^{(L)},]$ as input.  It then returns `grad` = $[\\frac{\\partial {\\bf{e}}}{\\partial W^{(1)}},\\frac{\\partial {\\bf{e}}}{\\partial W^{(2)}},\\ldots,\\frac{\\partial {\\bf{e}}}{\\partial W^{(L)}}]$. The return vector `grad` is computed by using the formula\n$$\\frac{\\partial {\\bf{e}}}{\\partial W^{(l)}} = {\\bf{x}}^{(l-1)}({\\bf{\\delta}}^{(l)})^T.$$\n\nNotice that ${\\bf{x}}^{(L)}$ is never used. \n\nWe can now do the complete test based on Example 7.1 from the book.","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"69966e","input":"### Homework 6\n#### Implementing a neural network\n\nIn this homework we will implement a feedforward sigmoidal neural network with $\\tanh$ as an activation function \"from the book\".\n\nIt will help to have with you the supplemental book chapter on neural nets, particularly the part on back-propagation.\n\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"7b6ccf","input":"The above was just using 2 of the 30 independent variables.\n\nLet's try it with 3. \n\n","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"8f68c3","input":"Notice that I have set the random number seed at 22 so that we all get the same results.  But in a working network you would want to use real random number for the weights so that you don't always start at the same initial weight vector (which might be a bad spot in the weight space).\n","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"b5eac0","input":"### Part 1: Initialize the network \n\nThe first task is to build the weight matrices from a description of the network.  As you can see from the docstring, `init_nn(D_l,sigma=1)` takes as input a numpy array of layer sizes `D_l` which is the \"architecture\" of the net.  It also takes a parameter $\\sigma$ which controls how close the initial weight vector is to the origin.  \n\nWhat we want to do is return a python list object `w` which represents\n\n$$\\bar{w} = [W^{(1)},W^{(2)},\\ldots,W^{(L)}].$$\n\nNote that $L$ can be derived from the length of `D_l`.  The matrices $W^{(l)}$ will be numpy matrices initialized with numbers sampled from the standard normal distribution (so use `np.random.randn`).  Each number needs to be divided by $\\sigma$ which can be done as one broadcast operation `W = W/sigma`. \n\nThroughout this assignment the worked Example 7.1 from the supplementary book chapter will be very helpful.  \n\nTo initialize that network with random weights we would do the following.\n\n","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"c47f65","input":"### Regression\n\nLet's try to make it do regression...\n\n","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"d3348c","input":"In the code below I train the NN on the above 2D data and compute the training error.\n\nCan you improve the training error by adjusting $\\eta$, the architecture, or the number of iterations?","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"d5fa82","input":"#### Sanity check...\n\nLet's make sure that the `sklearn` neural network with the same settings is performing more or less like the one we wrote...\n\nThe `sklearn` `score` function gives accuracy rather than error.\n\nSo subtract the `sklearn` score from 1 to get the error.  \n\nNotice that with `sklearn` you don't tell it the number of nodes in layer 0 or $L$.  That's because $d^{(L)}$ must be 1 for classification, and $d^{(0)}$ is implicit from X.  \n","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"d84d19","input":"### Part 5: Overfitting\n\nBelow I'm training and testing on the full breast cancer dataset.\n\nBut I'm overfitting.  Adjust the architecture and other settings so that overfitting isn't taking place.\n\nTry to get the lowest possible test error.\n","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"de539c","input":"### Nonlinear boundary\n\nIn class we talked about the \"universal approximation theorem\" which says that a neural network with 2 hidden layers can learn any decision boundary (approximately).  Let's give the NN some data that is not at all linearly separable and see what it comes up with. \n","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"ecd338","input":"### Part 3: Back-propagation\n\nThe reason back-propagation works to give $\\nabla e$ is kind of hard to understand, but the method itself isn't too hard to implement. The pseudocode in the book will guide you. Notice that the initialization of ${\\bf{\\delta}}^{(L)}$ depends on whether you're doing regression or classification.  You should put an `if` statement in your code that checks the truth value of `regression` and make the appropriate initialization. Also notice that ${\\bf{\\delta}}^{(0)}$ is not used, so please don't compute it.  Compare the output of the test case below to Example 7.1 in the book to see the exact form of `delta` the code should return. \n","pos":8,"type":"cell"}
{"id":0,"time":1590354031851,"type":"user"}
{"last_load":1590354032873,"type":"file"}