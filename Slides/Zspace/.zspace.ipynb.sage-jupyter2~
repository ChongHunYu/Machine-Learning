{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83697664},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"trust":false,"type":"settings"}
{"cell_type":"code","exec_count":12,"id":"4c2051","input":"import numpy as np\nimport matplotlib.pyplot as plt\nN=200\nnp.random.seed(43)\npts = np.random.randn(N,2)\nellipse = np.sum(pts**2,axis=1)-1 < 0\nyesE = pts[ellipse]\nnoE = pts[~ellipse]\nplt.scatter(yesE[:,0],yesE[:,1])\nplt.scatter(noE[:,0],noE[:,1])\nplt.title(\"A non-linearly separable set in the X space.\")\nplt.show()","output":{"0":{"data":{"image/png":"d9d887f48cfb38818349c01ab8c969243d2cdde6","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":13,"id":"418bb0","input":"pts2 = pts**2\nyesE = pts2[ellipse]\nnoE = pts2[~ellipse]\nplt.scatter(yesE[:,0],yesE[:,1])\nplt.scatter(noE[:,0],noE[:,1])\nplt.title(\"Becomes a linearly separable set in the Z space.\")\nplt.show()","output":{"0":{"data":{"image/png":"c8f2b5ae9988cc15fca965baed0f9fab8792592c","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":14,"id":"8ea2e8","input":"import mystuff as ms\n\nN=40\nnp.random.seed(430)\npts = np.random.randn(N,2)\nX = np.c_[np.ones(N),pts[:,0],pts[:,1]]\nw = [0,-8,4]\nG = np.sign(X.dot(w))>0\nG = G^np.random.choice([False,True],N,p=[.95,.05])\nB = ~G\ny = G*2.0-1\nGpts = pts[G]\nBpts = pts[B]\nplt.scatter(Gpts[:,0],Gpts[:,1])\nplt.scatter(Bpts[:,0],Bpts[:,1])\nplt.title(\"Linearly separable, but 5% flipped\")\nplt.show()","output":{"0":{"data":{"image/png":"a7b8254954c34d71f80c72795732343cce8a5b55","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":15,"id":"85c69a","input":"ms.lin_boundary(w,X,y)\n\ndef E_in(X,y,w):\n    mc = (np.sign(X.dot(w)) != y)\n    return np.sum(mc)/len(mc)\n\nprint(\"Error = {}\".format(E_in(X,y,w)))","output":{"0":{"data":{"image/png":"7c3e973c08b222d4b3fbd776608ce68c94f53ea3","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"name":"stdout","output_type":"stream","text":"Error = 0.075\n"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":16,"id":"5e53a7","input":"X1 = X[:,1]\nX2 = X[:,2]\n\nZ = np.c_[np.ones(N),X1,X2,X1**2,X2**2,X1*X2,X1**3,X2**3,X1**4,X2**4,X1**2*X2**2]","pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":17,"id":"39ab7b","input":"w = np.zeros(Z.shape[1])\nw,path = ms.grad_descent(w,Z,y,ms.fast_grad_lr,eta=0.1,max_iter=10000)","pos":10,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":18,"id":"0ed32a","input":"w","output":{"0":{"data":{"text/plain":"array([-1.7959337 , -5.57062047,  3.69222254,  4.18649149,  1.00112098,\n        2.37460724, -4.16546368, -0.18257122, -0.7820976 , -0.35814366,\n       -1.26008037])"},"exec_count":18,"output_type":"execute_result"}},"pos":11,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":19,"id":"758450","input":"def sigmoid(array):\n    \"\"\"Applies the sigmoid or logistic function to a numpy array\"\"\"\n    return 1/(1+np.exp(-array))\n\n\nxmin = np.min(X[:,1])-0.5\nxmax = np.max(X[:,1])+0.5\nymin = np.min(X[:,2])-0.5\nymax = np.max(X[:,2])+0.5\nx1 = np.arange(xmin,xmax,0.01)\nx2 = np.arange(ymin,ymax,0.01)\n\nx1v,x2v = np.meshgrid(x1,x2)\n\nvarz = [np.ones_like(x1v),x1v,x2v,x1v**2,x2v**2,x1v*x2v,x1v**3,x2v**3,x1v**4,x2v**4,x1v**2*x2v**2]\n\nz = np.zeros_like(x1v)\nfor ww,v in zip(w,varz):\n    z += ww*v\n\nzsoft = sigmoid(z)\n#z = np.sign(z)\nplt.contourf(x1v,x2v,zsoft,alpha=0.25)\nXg = X[y==1]\nXb = X[y==-1]\n\nplt.scatter(Xg[:,1],Xg[:,2],c=\"b\",alpha=0.5)\nplt.scatter(Xb[:,1],Xb[:,2],c='r',alpha=0.5)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\n\nplt.title(\"Contour plot of soft boundary\")\nplt.colorbar()\nplt.show()\n","output":{"0":{"data":{"image/png":"19dc05504581b97c3a72fdcf5af88cb43781b343","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":12,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":20,"id":"09863a","input":"    \nz = np.sign(z)\nplt.contourf(x1v,x2v,z,alpha=0.25)\nXg = X[y==1]\nXb = X[y==-1]\n\nplt.scatter(Xg[:,1],Xg[:,2],c=\"b\",alpha=0.5)\nplt.scatter(Xb[:,1],Xb[:,2],c='r',alpha=0.5)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\n\nplt.title(\"Contour plot of hard boundary\")\nplt.colorbar()\nplt.show()\n\nprint(\"Error = {}\".format(E_in(Z,y,w)))","output":{"0":{"data":{"image/png":"f52639c2cb780d19adf0dfa7bea799d003130d7b","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"name":"stdout","output_type":"stream","text":"Error = 0.025\n"}},"pos":13,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":21,"id":"67768a","input":"\nN=400\nnp.random.seed(430)\npts = np.random.randn(N,2)\nX = np.c_[np.ones(N),pts[:,0],pts[:,1]]\nwww = [0,-8,4]\nG = np.sign(X.dot(www))>0\nG = G^np.random.choice([False,True],N,p=[.95,.05])\nB = ~G\ny = G*2.0-1\n\nX1 = X[:,1]\nX2 = X[:,2]\n\nZ = np.c_[np.ones(N),X1,X2,X1**2,X2**2,X1*X2,X1**3,X2**3,X1**4,X2**4,X1**2*X2**2]\n\n\nz = np.sign(z)\nplt.contourf(x1v,x2v,z,alpha=0.25)\nXg = X[y==1]\nXb = X[y==-1]\n\nplt.scatter(Xg[:,1],Xg[:,2],c=\"b\",alpha=0.5)\nplt.scatter(Xb[:,1],Xb[:,2],c='r',alpha=0.5)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\n\nplt.title(\"Contour plot of hard boundary\")\nplt.colorbar()\nplt.show()\n\nprint(\"Error = {}\".format(E_in(Z,y,w)))","output":{"0":{"data":{"image/png":"cdb96305ce7e0ab38b0f493d76ed06f9c8b01c9e","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"name":"stdout","output_type":"stream","text":"Error = 0.0825\n"}},"pos":15,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":22,"id":"99cebe","input":"w = [0,-8,4]\n\nms.lin_boundary(w,X,y)\n\nprint(\"Error = {}\".format(E_in(X,y,w)))","output":{"0":{"data":{"image/png":"74f1562a2b0568642c364ba4b169902e9341b028","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"name":"stdout","output_type":"stream","text":"Error = 0.0375\n"}},"pos":16,"state":"done","type":"cell"}
{"cell_type":"code","id":"e21eda","input":"","pos":17,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"01e08c","input":"### Fitting\n\nWe now use logistic regression to fit this data in 10 dimensional space.\n","pos":9,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"24126f","input":"### Higher powers\n\nAbove we didn't add any new columns to the featurespace, we just transformed the existing ones.\n\nBelow we experiment with actually adding new derived columns.\n\nThis increases the expressive power of the classifier, but it can lead to overfitting.\n\nFirst we create a linearly separable dataset, but then randomly flip 5\\% of the labels.","pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2a3a6e","input":"### Observations\n\nWe succeeded in creating a more complex hypothesis class, which might fit the data better.\n\nBut how will it do on new data generated in the same way?\n\nThat is, more points generated by the original noisy line?\n\nWill it do better than the linear boundary, or worse?\n\n---\n\nSpoiler:  It will do worse.\n\nWe have lowered $E_{in}$ but increased $E_{out}$.\n\nWe have overfit the data.","pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"81c32a","input":"Now we apply the transformation\n\n\\begin{align}\n\\begin{bmatrix}\n   1 \\\\\n   x_{1} \\\\\n   x_{2}\n\\end{bmatrix} \n\\mapsto\n\\begin{bmatrix}\n   1 \\\\\n   x_{1} \\\\\n   x_{2} \\\\\n   x_{1}^2 \\\\\n   x_{2}^2 \\\\\n   x_1x_2 \\\\\n   x_1^3 \\\\\n   x_2^3 \\\\\n   x_1^4 \\\\\n   x_2^4 \\\\\n   x_1^2x_2^2 \\\\\n\\end{bmatrix} \n\\end{align}\n\nThis has the effect of embedding $\\mathbb{R}^2$ in $\\mathbb{R}^{10}$.\n\nThe embedding is \"wrinkly\" so that subsets cut out by \"flat\" hyperplanes in $\\mathbb{R}^{10}$ actually correspond to nonlinear patterns back in $\\mathbb{R}^2$.\n\n","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c91615","input":"### A non-linearly separable set\n\nConsider the set of points shown below.\n\nPositive instances are inside the unit circle $x_1^2+x_2^2 < 1$.\n\nAll points outside the circle are negative instances.","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fd6471","input":"### A transformation of variables\n\nNow we apply the transformation\n\n\\begin{align}\n\\begin{bmatrix}\n   1 \\\\\n   x_{1} \\\\\n   x_{2}\n\\end{bmatrix} \n\\mapsto\n\\begin{bmatrix}\n   1 \\\\\n   x_{1}^2 \\\\\n   x_{2}^2\n\\end{bmatrix} \n\\end{align}\n\nThe dataset is now linearly separable in the transform space, because we can express\n\n$x_1^2+x_2^2 - 1=0$\n\nas\n\n$\\bar{w}^T\\bar{x} = 0$\n\nwhere $\\bar{w} =\\begin{bmatrix}\n   -1 \\\\\n   1 \\\\\n   1\n\\end{bmatrix} $.\n\nThus\n\n$sign(\\bar{w}^T\\bar{x})$\n\ngives the correct labels.\n\n\n","pos":2,"state":"done","type":"cell"}
{"id":0,"time":1585062290128,"type":"user"}
{"last_load":1585060695824,"type":"file"}