{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83419136},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"type":"settings"}
{"cell_type":"code","exec_count":100,"id":"8ec13a","input":"model = grid_search.best_estimator_\n\nmodel.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.8811188811188811"},"exec_count":100,"output_type":"execute_result"}},"pos":12,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":101,"id":"46add0","input":"bc_predict(model,X,y,0,.5,0,.09)\n","output":{"0":{"data":{"image/png":"d3921500af781ab00271a823a7329b8d168bc77b","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"data":{"image/png":"3dec454777fe803a57ad14139488455b5fef99da","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"2":{"data":{"image/png":"893d8bd97eccc8fed8109347038cf78d436fa3ef","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":13,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":102,"id":"1fdf25","input":"from sklearn.tree import export_graphviz\n\nexport_graphviz(\n        model,\n        out_file=\"bc.dot\",\n        feature_names=['x1','x2'],\n        class_names=['m','b'],\n        rounded=True,\n        filled=True\n    )","pos":14,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":103,"id":"a885ff","input":"!dot -Tpng bc.dot -o bc.png","pos":15,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":104,"id":"9d9393","input":"col_names = [\"ID\",\"Diagnosis\",\"mean_radius\",\"std_err_radius\",\"worst_radius\",\n            \"mean_texture\",\"std_err_texture\",\"worst_texture\",\n            \"mean_perimeter\",\"std_err_perimeter\",\"worst_perimeter\",\n            \"mean_area\",\"std_err_area\",\"worst_area\",\n            \"mean_smoothness\",\"std_err_smoothness\",\"worst_smoothness\",\n            \"mean_compactness\",\"std_err_compactness\",\"worst_compactness\",\n            \"mean_concavity\",\"std_err_concavity\",\"worst_concavity\",\n            \"mean_concave_pts\",\"std_err_concave_pts\",\"worst_concave_pts\",\n            \"mean_symmetry\",\"std_err_symmetry\",\"worst_symmetry\",\n            \"mean_fractal_dim\",\"std_err_fractal_dim\",\"worst_fractal_dim\"]\nX = np.copy(D[:,2:])\ny = 2*D[:,1] -1  # so that y in {-1,1}, not {0,1}\n\nnames = col_names[2:]\nX.shape[1],len(names)","output":{"0":{"data":{"text/plain":"(30, 30)"},"exec_count":104,"output_type":"execute_result"}},"pos":17,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":105,"id":"6b756d","input":"\nX_train,X_test,y_train,y_test = train_test_split(X,y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","pos":18,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":106,"id":"c79dda","input":"model = DecisionTreeClassifier()\n\nparam_grid = [{'max_depth':[3,9,25],'max_features':[1,8,16,30],'min_weight_fraction_leaf':[0,.03,.1,.2]}]\n\n\ngrid_search = GridSearchCV(model,param_grid,cv=5)\n\ngrid_search.fit(X_train,y_train)","output":{"0":{"data":{"text/plain":"GridSearchCV(cv=5, error_score=nan,\n             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features=None,\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              presort='deprecated',\n                                              random_state=None,\n                                              splitter='best'),\n             iid='deprecated', n_jobs=None,\n             param_grid=[{'max_depth': [3, 9, 25],\n                          'max_features': [1, 8, 16, 30],\n                          'min_weight_fraction_leaf': [0, 0.03, 0.1, 0.2]}],\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"},"exec_count":106,"output_type":"execute_result"}},"pos":19,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":107,"id":"d0b310","input":"grid_search.best_params_\n","output":{"0":{"data":{"text/plain":"{'max_depth': 25, 'max_features': 30, 'min_weight_fraction_leaf': 0}"},"exec_count":107,"output_type":"execute_result"}},"pos":20,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":108,"id":"5e6efa","input":"model = grid_search.best_estimator_\nmodel.fit(X,y)\nexport_graphviz(\n        model,\n        out_file=\"bc_full3.dot\",\n        feature_names=names,\n        class_names=['b','m'],\n        rounded=True,\n        filled=True\n    )","pos":21,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":109,"id":"2ef392","input":"!dot -Tpng bc_full3.dot -o bc_full3.png","pos":22,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":110,"id":"e244be","input":"model.fit(X_train,y_train)\nmodel.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.916083916083916"},"exec_count":110,"output_type":"execute_result"}},"pos":24,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":111,"id":"9526a2","input":"from sklearn.ensemble import BaggingClassifier\nbag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=4),max_features=0.6,n_estimators=1000,max_samples=300,bootstrap=True,n_jobs=-1,oob_score = True)\nbag_clf.fit(X_train,y_train)\nbag_clf.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.951048951048951"},"exec_count":111,"output_type":"execute_result"}},"pos":25,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":112,"id":"fbcd89","input":"### OOB is pretty close to test error, without using test set.\n### Can use this as a kind of cross-validation\n\nbag_clf.oob_score_","output":{"0":{"data":{"text/plain":"0.9553990610328639"},"exec_count":112,"output_type":"execute_result"}},"pos":26,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":113,"id":"af36ab","input":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\nrf.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.9440559440559441"},"exec_count":113,"output_type":"execute_result"}},"pos":27,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":114,"id":"a7aa21","input":"## This is equivalent to the random forest classifier\n\nbag_clf = BaggingClassifier(DecisionTreeClassifier(max_leaf_nodes=16,splitter=\"random\"),n_estimators=500,max_samples=1.0,bootstrap=True,n_jobs=-1,oob_score = True)\nbag_clf.fit(X_train,y_train)\nbag_clf.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.951048951048951"},"exec_count":114,"output_type":"execute_result"}},"pos":28,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":115,"id":"e78d0b","input":"best_features = []\nfor nm,score in zip(names,rf.feature_importances_):\n    best_features.append((nm,score))","pos":29,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":116,"id":"eef413","input":"best_features.sort(key=lambda x:x[1],reverse=True)","pos":30,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":117,"id":"d37c98","input":"best_features","output":{"0":{"data":{"text/plain":"[('std_err_concave_pts', 0.18220802202944764),\n ('worst_concave_pts', 0.1316207529061084),\n ('mean_fractal_dim', 0.11285732156134179),\n ('worst_concavity', 0.09645242396675695),\n ('std_err_perimeter', 0.0757811495336089),\n ('mean_radius', 0.0596122287876792),\n ('worst_radius', 0.056108054829240785),\n ('mean_texture', 0.044225416002187205),\n ('mean_perimeter', 0.040939549614924055),\n ('std_err_smoothness', 0.023298339478817737),\n ('worst_symmetry', 0.022869282741510046),\n ('mean_concave_pts', 0.021354019071255625),\n ('mean_smoothness', 0.014524231694099096),\n ('std_err_radius', 0.013501399284253026),\n ('std_err_area', 0.012159206328667085),\n ('std_err_symmetry', 0.011719575283667101),\n ('mean_symmetry', 0.009860783507295022),\n ('worst_fractal_dim', 0.009445216316412465),\n ('worst_texture', 0.008794220890269003),\n ('std_err_fractal_dim', 0.007931268844919268),\n ('worst_perimeter', 0.00595044159453993),\n ('std_err_concavity', 0.005584038918306733),\n ('worst_compactness', 0.0051146203176180615),\n ('std_err_texture', 0.005018125960237723),\n ('mean_concavity', 0.004276560750336739),\n ('std_err_compactness', 0.004223074591754414),\n ('worst_smoothness', 0.00419193993043608),\n ('mean_compactness', 0.0036091433108937933),\n ('worst_area', 0.003574867746322512),\n ('mean_area', 0.0031947242070937175)]"},"exec_count":117,"output_type":"execute_result"}},"pos":31,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":118,"id":"31f9e8","input":"# Code stolen from here:\n#https://stats.stackexchange.com/questions/157220/how-to-use-decision-stump-as-weak-learner-in-adaboost#157756\n\n# input: dataset X and labels y (in {+1, -1})\n\ndef adaboost(X,y,num_iterations=500):\n    hypotheses = []\n    hypothesis_weights = []\n\n    N = X.shape[0]\n    d = np.ones(N) / N\n\n    for t in range(num_iterations):\n        h = DecisionTreeClassifier(max_depth=1)\n\n        h.fit(X, y, sample_weight=d)\n        pred = h.predict(X)\n\n        eps = d.dot(pred != y)\n        alpha = (np.log(1 - eps) - np.log(eps)) / 2\n\n        d = d * np.exp(- alpha * y * pred)\n        d = d / d.sum()\n\n        hypotheses.append(h)\n        hypothesis_weights.append(alpha)\n    return hypotheses,hypothesis_weights\n\ndef adapredict(X,hypotheses,hypotheses_weight):\n    N = X.shape[0]\n    y = np.zeros(N)\n    for (h, alpha) in zip(hypotheses, hypotheses_weight):\n        y = y + alpha * h.predict(X)\n    y = np.sign(y)    \n    return y\n    \nh,hw = adaboost(X_train,y_train)\ny_train_hat = adapredict(X_train,h,hw)\ny_test_hat = adapredict(X_test,h,hw)\nprint(\"Train error: {}\".format(np.mean(y_train_hat != y_train)))\nprint(\"Test error: {}\".format(np.mean(y_test_hat != y_test)))\nprint(\"Test accuracy: {}\".format(np.mean(y_test_hat == y_test)))","output":{"0":{"name":"stdout","output_type":"stream","text":"Train error: 0.0\nTest error: 0.03496503496503497\nTest accuracy: 0.965034965034965\n"}},"pos":33,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":119,"id":"07fac8","input":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=500,algorithm=\"SAMME.R\",learning_rate=0.5)\nada.fit(X_train,y_train)\nada.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.9440559440559441"},"exec_count":119,"output_type":"execute_result"}},"pos":38,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":120,"id":"406dca","input":"best_features = []\nfor nm,score in zip(names,ada.feature_importances_):\n    best_features.append((nm,score))\nbest_features.sort(key=lambda x:x[1],reverse=True)    \nbest_features","output":{"0":{"data":{"text/plain":"[('mean_compactness', 0.114),\n ('worst_symmetry', 0.09),\n ('std_err_smoothness', 0.08),\n ('std_err_radius', 0.074),\n ('mean_fractal_dim', 0.072),\n ('mean_symmetry', 0.054),\n ('worst_compactness', 0.052),\n ('mean_concave_pts', 0.05),\n ('worst_texture', 0.046),\n ('worst_concavity', 0.042),\n ('mean_texture', 0.036),\n ('mean_smoothness', 0.036),\n ('std_err_area', 0.032),\n ('std_err_perimeter', 0.03),\n ('std_err_fractal_dim', 0.03),\n ('std_err_concave_pts', 0.028),\n ('std_err_concavity', 0.024),\n ('std_err_texture', 0.016),\n ('worst_smoothness', 0.014),\n ('worst_concave_pts', 0.014),\n ('worst_fractal_dim', 0.014),\n ('worst_perimeter', 0.012),\n ('worst_area', 0.01),\n ('mean_perimeter', 0.008),\n ('mean_area', 0.008),\n ('mean_concavity', 0.006),\n ('std_err_symmetry', 0.006),\n ('worst_radius', 0.002),\n ('mean_radius', 0.0),\n ('std_err_compactness', 0.0)]"},"exec_count":120,"output_type":"execute_result"}},"pos":39,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":127,"id":"3c5c08","input":"\n### In this code we remember the old weight vectors for the training data\n### We'll observe how they change\n\ndef adaboost_dbg(X,y,num_iterations=500):\n    hypotheses = []\n    hypothesis_weights = []\n    D = []\n    N = X.shape[0]\n    d = np.ones(N) / N\n    \n    for t in range(num_iterations):\n        D.append(d)\n        h = DecisionTreeClassifier(max_depth=1)\n\n        h.fit(X, y, sample_weight=d)\n        pred = h.predict(X)\n\n        eps = d.dot(pred != y)\n        alpha = (np.log(1 - eps) - np.log(eps)) / 2\n\n        d = d * np.exp(- alpha * y * pred)\n        d = d / d.sum()\n\n        hypotheses.append(h)\n        hypothesis_weights.append(alpha)\n    return hypotheses,hypothesis_weights,D\n","pos":34,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":128,"id":"3821de","input":"h,hw,D = adaboost_dbg(X_train,y_train,num_iterations=5)\ny_train_hat = adapredict(X_train,h,hw)\ny_test_hat = adapredict(X_test,h,hw)\nprint(\"Train error: {}\".format(np.mean(y_train_hat != y_train)))\nprint(\"Test error: {}\".format(np.mean(y_test_hat != y_test)))\nprint(\"Test accuracy: {}\".format(np.mean(y_test_hat == y_test)))\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Train error: 0.025821596244131457\nTest error: 0.06293706293706294\nTest accuracy: 0.9370629370629371\n"}},"pos":35,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":143,"id":"2f27f5","input":"### Train on a small amount of data so we can study how it works.\n\n### Look at this crazy accuracy for 5 iterations and 75 training points!\n\nh,hw,D = adaboost_dbg(X_train[:75],y_train[:75],num_iterations=5)\ny_train_hat = adapredict(X_train,h,hw)\ny_test_hat = adapredict(X_test,h,hw)\nprint(\"Train error: {}\".format(np.mean(y_train_hat != y_train)))\nprint(\"Test error: {}\".format(np.mean(y_test_hat != y_test)))\nprint(\"Test accuracy: {}\".format(np.mean(y_test_hat == y_test)))\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Train error: 0.08215962441314555\nTest error: 0.11188811188811189\nTest accuracy: 0.8881118881118881\n"}},"pos":36,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":149,"id":"7bcafe","input":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\ni = 0\nfor hh,hhw,d in zip(h,hw,D):\n    stumpname = \"stump_{}\".format(i)\n    export_graphviz(hh,out_file=\"{}.dot\".format(stumpname),feature_names=names,class_names=['b','m'],rounded=True,filled=True)\n    !dot -Tpng {stumpname}.dot -o {stumpname}.png\n    img=mpimg.imread('{}.png'.format(stumpname))\n    imgplot = plt.imshow(img)\n    print(\"Stump {}\".format(i))\n    plt.show()\n    print(\"Weighted data:\")\n    print(d.reshape(15,5))\n    print(\"Misclassifications:\")\n    yyhat = hh.predict(X_train[:75])\n    print((yyhat !=y_train[:75]).reshape(15,5))\n    print(\"Stump weight: {}\".format(hhw))\n    i += 1","output":{"0":{"name":"stdout","output_type":"stream","text":"Stump 0\n"},"1":{"data":{"image/png":"8d285d5fef757964ea7d1606100c37ffaddc6022","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"10":{"name":"stdout","output_type":"stream","text":"Weighted data:\n[[0.00116568 0.00116568 0.00116568 0.00116568 0.00116568]\n [0.00116568 0.00116568 0.00116568 0.00116568 0.00116568]\n [0.00940317 0.00116568 0.00940317 0.00940317 0.00116568]\n [0.00116568 0.00116568 0.00116568 0.00116568 0.00116568]\n [0.0198166  0.00116568 0.00940317 0.0090799  0.00116568]\n [0.00116568 0.00116568 0.00116568 0.00116568 0.0090799 ]\n [0.0198166  0.00116568 0.0198166  0.0090799  0.0090799 ]\n [0.00116568 0.0090799  0.00116568 0.00116568 0.15435835]\n [0.00116568 0.00116568 0.0090799  0.00116568 0.0090799 ]\n [0.00116568 0.00116568 0.00116568 0.00940317 0.0198166 ]\n [0.0198166  0.0090799  0.00116568 0.0090799  0.00116568]\n [0.00116568 0.00116568 0.0090799  0.0198166  0.00116568]\n [0.0090799  0.2256761  0.00116568 0.00116568 0.00116568]\n [0.15435835 0.00116568 0.02797638 0.00116568 0.0090799 ]\n [0.02797638 0.07324455 0.00116568 0.00116568 0.0090799 ]]\nMisclassifications:\n[[ True False False False False]\n [ True False  True False False]\n [ True False  True  True  True]\n [ True False False  True False]\n [False False  True False False]\n [False  True False False  True]\n [False False False False False]\n [False False False False False]\n [False False  True  True False]\n [ True  True  True  True False]\n [False  True False False False]\n [False False False False  True]\n [ True False False False False]\n [False False  True False False]\n [ True False False False False]]\nStump weight: 0.8545657249814039\n"},"2":{"name":"stdout","output_type":"stream","text":"Weighted data:\n[[0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]\n [0.01333333 0.01333333 0.01333333 0.01333333 0.01333333]]\nMisclassifications:\n[[False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False  True False False False]\n [False False  True False False]\n [ True False False False False]]\nStump weight: 1.5890269151739727\nStump 1\n"},"3":{"data":{"image/png":"543f46f8a3b4ca8340ad942b20404100f9047ab3","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"4":{"name":"stdout","output_type":"stream","text":"Weighted data:\n[[0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.16666667 0.00694444 0.00694444 0.00694444]\n [0.00694444 0.00694444 0.16666667 0.00694444 0.00694444]\n [0.16666667 0.00694444 0.00694444 0.00694444 0.00694444]]\nMisclassifications:\n[[False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [ True False False False False]\n [False False False False False]\n [ True False  True False False]\n [False False False False  True]\n [False False False False False]\n [False False False False  True]\n [ True False False False False]\n [False False False  True False]\n [False False False False False]\n [ True False False False False]\n [False False False False False]]\nStump weight: 1.4166066720281079\nStump 2\n"},"5":{"data":{"image/png":"d6e1f9a07d401f78e308136d9dbcf1b6572ba839","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"6":{"name":"stdout","output_type":"stream","text":"Weighted data:\n[[0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.0625     0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.0625     0.00367647 0.0625     0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.0625    ]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.00367647 0.0625    ]\n [0.0625     0.00367647 0.00367647 0.00367647 0.00367647]\n [0.00367647 0.00367647 0.00367647 0.0625     0.00367647]\n [0.00367647 0.08823529 0.00367647 0.00367647 0.00367647]\n [0.0625     0.00367647 0.08823529 0.00367647 0.00367647]\n [0.08823529 0.00367647 0.00367647 0.00367647 0.00367647]]\nMisclassifications:\n[[False False False False False]\n [False False False False False]\n [ True False  True  True False]\n [False False False False False]\n [False False  True False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False  True False]\n [False False False False False]\n [False False False False False]\n [False  True False False False]\n [False False False False False]\n [False  True False False False]]\nStump weight: 1.0438701722472654\nStump 3\n"},"7":{"data":{"image/png":"a232beba459fbc932422de5a93ffd45e350d8f1e","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"8":{"name":"stdout","output_type":"stream","text":"Weighted data:\n[[0.00206612 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.01666667 0.00206612 0.01666667 0.01666667 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.03512397 0.00206612 0.01666667 0.00206612 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.03512397 0.00206612 0.03512397 0.00206612 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.00206612 0.03512397]\n [0.00206612 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.01666667 0.03512397]\n [0.03512397 0.00206612 0.00206612 0.00206612 0.00206612]\n [0.00206612 0.00206612 0.00206612 0.03512397 0.00206612]\n [0.00206612 0.4        0.00206612 0.00206612 0.00206612]\n [0.03512397 0.00206612 0.04958678 0.00206612 0.00206612]\n [0.04958678 0.01666667 0.00206612 0.00206612 0.00206612]]\nMisclassifications:\n[[False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False False False]\n [False False False  True False]\n [False False False False  True]\n [False False False  True  True]\n [False  True False False  True]\n [False False  True False  True]\n [False False False False False]\n [False  True False  True False]\n [False False  True False False]\n [ True False False False False]\n [ True False False False  True]\n [False  True False False  True]]\nStump weight: 1.0263784671389968\nStump 4\n"},"9":{"data":{"image/png":"6c435400876546d23f556876b4eae60b1e406d67","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":37,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":89,"id":"24884d","input":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\n\n###\n\nD = np.loadtxt(open(\"num_data.txt\", \"rb\"), delimiter=\",\", skiprows=0)\n\n\nx  = D[:,8]\ny  = D[:,20]\n\nmalignant = D[:,1]==1  ## Column 1 represents benign (0) or malignant (1)\n\n\nxm = x[malignant]\nym = y[malignant]\n\nbenign = D[:,1]==0\nxb = x[benign]\nyb = y[benign]\n\nplt.scatter(xm,ym,label=\"malignant\",alpha=0.3)\nplt.scatter(xb,yb,label=\"benign\",alpha=0.3)\n\nplt.legend()\nplt.show()","output":{"0":{"data":{"image/png":"aef8528884c162f51090d8cea9ff2c05fd2177b0","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":90,"id":"d12143","input":"X = np.ones(D.shape[0]*3).reshape(D.shape[0],3)\nX[:,1] = D[:,20]\nX[:,2] = D[:,8]\nX = StandardScaler().fit_transform(X)\nmalignant = D[:,1]==1  ## Column 1 represents benign (0) or malignant (1)\ny = 2*malignant -1  # so that y in {-1,1}, not {0,1}\n","pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":91,"id":"3821ad","input":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nmodel.fit(X,y)\n\n","output":{"0":{"data":{"text/plain":"DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')"},"exec_count":91,"output_type":"execute_result"}},"pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":92,"id":"72be05","input":"\ndef bc_predict(model,X,y,xl=-2,xr=5,yl=-2,yr=7):\n    g = model.predict(X)\n\n    xm = X[:,X.shape[1]-1][malignant]\n    ym = X[:,X.shape[1]-2][malignant]\n\n    xb = X[:,X.shape[1]-1][benign]\n    yb = X[:,X.shape[1]-2][benign]\n\n\n    plt.scatter(xm,ym,label=\"malignant\",alpha=0.13)\n    plt.scatter(xb,yb,label=\"benign\",alpha=0.13)\n    plt.title(\"Misclassified points (in red)\")\n    plt.scatter(X[g!=y][:,X.shape[1]-1],X[g!=y][:,X.shape[1]-2],c='red',alpha=0.2)\n    plt.show()\n    plt.title(\"All points with correct classification\")\n    plt.scatter(xm,ym,label=\"malignant\",alpha=0.13)\n    plt.scatter(xb,yb,label=\"benign\",alpha=0.13)\n\n    plt.show()\n    num = 100\n    xc = np.linspace(xl,xr,num)\n    yc = np.linspace(yl,yr,num)\n    cart_prod = np.transpose([np.tile(xc, len(yc)), np.repeat(yc, len(xc))])\n    if X.shape[1]==2:\n        Xc = np.c_[cart_prod[:,1],cart_prod[:,0]]\n    else:\n        Xc = np.c_[np.ones(len(cart_prod)),cart_prod[:,1],cart_prod[:,0]]\n    #scaler = StandardScaler()\n    #X = scaler.fit_transform(X)\n    #Xc = scaler.transform(Xc)\n    #X,Xc = scaler(X,Xc)\n\n    #gc = predict_all(Xc,w,regression)\n    gc = model.predict(Xc)\n\n    says_yeah = gc == 1\n    says_no = ~says_yeah\n\n\n    plt.title(\"Decision boundary of Model\")\n    plt.scatter(xm,ym,label=\"malignant\",alpha=0.43)\n    plt.scatter(xb,yb,label=\"benign\",alpha=0.43)\n    plt.scatter(cart_prod[says_yeah][:,0],cart_prod[says_yeah][:,1],label=\"predict yes\",alpha=0.05,color='g')\n    plt.scatter(cart_prod[says_no][:,0],cart_prod[says_no][:,1],label=\"predict no\",alpha=0.05,color='r')\n\n    plt.legend()\n    plt.show()\n\nbc_predict(model,X,y)","output":{"0":{"data":{"image/png":"6a33d7d0ece97d0897045b22b87f0bb8fbc57b5b","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"1":{"data":{"image/png":"d431f162fdf053e33b45824b273dfca17bbdbd51","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"},"2":{"data":{"image/png":"95bac832f3d005530fec136fdbb80135f10b9fdc","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"},"output_type":"display_data"}},"pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":93,"id":"69d127","input":"from sklearn.model_selection import train_test_split\n\nX = np.ones(D.shape[0]*2).reshape(D.shape[0],2)\nX[:,0] = D[:,20]\nX[:,1] = D[:,8]\nmalignant = D[:,1]==1  ## Column 1 represents benign (0) or malignant (1)\ny = 2*malignant -1  # so that y in {-1,1}, not {0,1}\n\nX_train,X_test,y_train,y_test = train_test_split(X,y)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":94,"id":"d7b577","input":"model = DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\nmodel.score(X_train,y_train)","output":{"0":{"data":{"text/plain":"1.0"},"exec_count":94,"output_type":"execute_result"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":95,"id":"0a727a","input":"model.score(X_test,y_test)","output":{"0":{"data":{"text/plain":"0.7972027972027972"},"exec_count":95,"output_type":"execute_result"}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":96,"id":"3b6c4b","input":"model","output":{"0":{"data":{"text/plain":"DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')"},"exec_count":96,"output_type":"execute_result"}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":97,"id":"adc6c9","input":"X_train.shape[1]","output":{"0":{"data":{"text/plain":"2"},"exec_count":97,"output_type":"execute_result"}},"pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":98,"id":"4d88e3","input":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [{'max_depth':[3,6,9],'max_features':[1,2],'min_weight_fraction_leaf':[0,.1,.2,.3]}]\n\n\ngrid_search = GridSearchCV(model,param_grid,cv=5)\n\ngrid_search.fit(X_train,y_train)\n","output":{"0":{"data":{"text/plain":"GridSearchCV(cv=5, error_score=nan,\n             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features=None,\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              presort='deprecated',\n                                              random_state=None,\n                                              splitter='best'),\n             iid='deprecated', n_jobs=None,\n             param_grid=[{'max_depth': [3, 6, 9], 'max_features': [1, 2],\n                          'min_weight_fraction_leaf': [0, 0.1, 0.2, 0.3]}],\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"},"exec_count":98,"output_type":"execute_result"}},"pos":10,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":99,"id":"b3e589","input":"grid_search.best_params_","output":{"0":{"data":{"text/plain":"{'max_depth': 3, 'max_features': 2, 'min_weight_fraction_leaf': 0.1}"},"exec_count":99,"output_type":"execute_result"}},"pos":11,"state":"done","type":"cell"}
{"cell_type":"code","id":"017ac0","input":"","pos":42,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1a5554","input":"### Gradient Boosting\n\nThis image is from Geron (https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb)\n","pos":40,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2209ee","input":"![img](geron.png)","pos":41,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"70acb8","input":"### Boosting\n\n(see Hands on Machine Learning by Geron 1st ed, ch. 7)\n\nBoosting is an ensemble method that tries to combine many weak learners into a strong learner.\n\nUsually the ensemble is not independently drawn as in the case of bagging or a random forest.\n\nRather each subsequent \"tree\" in the forest is chosen to correct the failings of the previous trees. \n\nWe will discuss two main approaches:\n\n* Adaboost\n* Gradient Boost\n\n### Adaboost\n\nAdaboost outputs a series of hypotheses.\n\nEach hypothesis has been constructed to correct the mistakes of its predecessors.\n\nInstances that are persistently misclassified acquire higher and higher weight.\n\nEach hypothesis in the ensemble is also weighted according to its weighted accuracy.\n\nIn the final prediction the hypotheses have a weighted vote.\n\n![img](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F1700%2F0*paPv7vXuq4eBHZY7.png&f=1&nofb=1)\n\n","pos":32,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"737c51","input":"![img](bc_full3.png)","pos":23,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c97c93","input":"![img](bc.png)","pos":16,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e6f5a2","input":"### Ensemble methods\n\nEnsemble techniques use a combination of multiple models to make one big model.  \n\nOften the aggregated model is \"smarter\" than any individual model.\n\nImagine 1000 models that are each right 51% of the time.\n\nEach model is \"weak\".  \n\nBut if each model is wrong **independently** of the others, the *mode* prediction is almost certainly correct.\n\nHowever if the models are correlated then the mode prediction may be just as bad as the constituent models.\n\n---\n\n#### Random forest\n\nOne particularly powerful example is the \"random forest\".\n\nThis approach seeks to create a diverse set of decision trees.\n\nThe models are given slightly different features and data to increase the diversity.\n\nThen they all \"vote\" and collectively their predictions tend to yield good results.\n\n---\n\n","pos":0,"state":"done","type":"cell"}
{"id":0,"time":1589749544334,"type":"user"}
{"last_load":1589394123259,"type":"file"}